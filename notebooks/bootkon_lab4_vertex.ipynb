{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ad2b88b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lab 4: Machine Learning with Vertex AI\n",
    "\n",
    "Author: \n",
    "* Fabian Hirschmann\n",
    "* Wissem Khlifi\n",
    "\n",
    "Welcome back ðŸ‘‹ðŸ˜. During this lab, you will train a machine learning model on the data set you already know. Then, we will create a MLOps pipeline to automate this process.\n",
    "\n",
    "In a Jupyter Notebook, you can press `Shift + Return` to execute the current code junk and jump to the next one.\n",
    "\n",
    "First, let's set a few variables and perform some Python imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7bf0314c-770c-41fe-be57-f41eb17bf48a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1337)\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from google.cloud import aiplatform, bigquery\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "\n",
    "REGION = \"us-central1\"\n",
    "BQ_DATASET = \"ml_datasets\"\n",
    "BQ_TABLE = \"ulb_fraud_detection_dataproc\"\n",
    "BQ_SOURCE = f\"{PROJECT_ID}.{BQ_DATASET}.{BQ_TABLE}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010b46cf-c829-4439-9151-3722c290d5b8",
   "metadata": {},
   "source": [
    "If you get warnings about GPUs not being available -- that's fine.\n",
    "\n",
    "The requirements were automatically installed by the `bootstrap_workbench.sh` script we specified when we created this Workbench instance. However, if the above command fails due to import errors, uncomment the next chunk, run it, and then restart the kernel (`Kernel > Restart Kernel` in the menu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "caad0bb3-7432-45b5-bf1a-eb7c0214b5c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d9ce43-7912-4fcc-98ee-e30ae961e43e",
   "metadata": {},
   "source": [
    "The next chunk represents the source table in BigQuery we will be working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fc71c4c-6a9f-47bb-81f3-ed4ec4ce38b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'astute-ace-336608.ml_datasets.ulb_fraud_detection_dataproc'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BQ_SOURCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a8cb35-8c90-4378-a592-fd28ffa6d1a5",
   "metadata": {},
   "source": [
    "Let's have a look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e6ea1163",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=f\"{PROJECT_ID}-bucket\")\n",
    "bq = bigquery.Client(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07455370-2100-469e-9a87-09963c593437",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = bq.query(f\"SELECT * FROM `{BQ_SOURCE}`\").to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e3aaa1-4083-4e35-8c70-6ecbf41fac76",
   "metadata": {},
   "source": [
    "Let's have a look at the data set in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "590bc934-a254-4ee3-9dc4-1a21cf57648d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>282.0</td>\n",
       "      <td>-0.356466</td>\n",
       "      <td>0.725418</td>\n",
       "      <td>1.971749</td>\n",
       "      <td>0.831343</td>\n",
       "      <td>0.369681</td>\n",
       "      <td>-0.107776</td>\n",
       "      <td>0.751610</td>\n",
       "      <td>-0.120166</td>\n",
       "      <td>-0.420675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020804</td>\n",
       "      <td>0.424312</td>\n",
       "      <td>-0.015989</td>\n",
       "      <td>0.466754</td>\n",
       "      <td>-0.809962</td>\n",
       "      <td>0.657334</td>\n",
       "      <td>-0.043150</td>\n",
       "      <td>-0.046401</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14332.0</td>\n",
       "      <td>1.071950</td>\n",
       "      <td>0.340678</td>\n",
       "      <td>1.784068</td>\n",
       "      <td>2.846396</td>\n",
       "      <td>-0.751538</td>\n",
       "      <td>0.403028</td>\n",
       "      <td>-0.734920</td>\n",
       "      <td>0.205807</td>\n",
       "      <td>1.092726</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.169632</td>\n",
       "      <td>-0.113604</td>\n",
       "      <td>0.067643</td>\n",
       "      <td>0.468669</td>\n",
       "      <td>0.223541</td>\n",
       "      <td>-0.112355</td>\n",
       "      <td>0.014015</td>\n",
       "      <td>0.021504</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32799.0</td>\n",
       "      <td>1.153477</td>\n",
       "      <td>-0.047859</td>\n",
       "      <td>1.358363</td>\n",
       "      <td>1.480620</td>\n",
       "      <td>-1.222598</td>\n",
       "      <td>-0.481690</td>\n",
       "      <td>-0.654461</td>\n",
       "      <td>0.128115</td>\n",
       "      <td>0.907095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125514</td>\n",
       "      <td>0.480049</td>\n",
       "      <td>-0.025964</td>\n",
       "      <td>0.701843</td>\n",
       "      <td>0.417245</td>\n",
       "      <td>-0.257691</td>\n",
       "      <td>0.060115</td>\n",
       "      <td>0.035332</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35799.0</td>\n",
       "      <td>-0.769798</td>\n",
       "      <td>0.622325</td>\n",
       "      <td>0.242491</td>\n",
       "      <td>-0.586652</td>\n",
       "      <td>0.527819</td>\n",
       "      <td>-0.104512</td>\n",
       "      <td>0.209909</td>\n",
       "      <td>0.669861</td>\n",
       "      <td>-0.304509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152738</td>\n",
       "      <td>0.255654</td>\n",
       "      <td>-0.130237</td>\n",
       "      <td>-0.660934</td>\n",
       "      <td>-0.493374</td>\n",
       "      <td>0.331855</td>\n",
       "      <td>-0.011101</td>\n",
       "      <td>0.049089</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36419.0</td>\n",
       "      <td>1.047960</td>\n",
       "      <td>0.145048</td>\n",
       "      <td>1.624573</td>\n",
       "      <td>2.932652</td>\n",
       "      <td>-0.726574</td>\n",
       "      <td>0.690451</td>\n",
       "      <td>-0.627288</td>\n",
       "      <td>0.278709</td>\n",
       "      <td>0.318434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078499</td>\n",
       "      <td>0.658942</td>\n",
       "      <td>-0.067810</td>\n",
       "      <td>0.476882</td>\n",
       "      <td>0.526830</td>\n",
       "      <td>0.219902</td>\n",
       "      <td>0.070627</td>\n",
       "      <td>0.028488</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>154599.0</td>\n",
       "      <td>0.667714</td>\n",
       "      <td>3.041502</td>\n",
       "      <td>-5.845112</td>\n",
       "      <td>5.967587</td>\n",
       "      <td>0.213863</td>\n",
       "      <td>-1.462923</td>\n",
       "      <td>-2.688761</td>\n",
       "      <td>0.677764</td>\n",
       "      <td>-3.447596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329760</td>\n",
       "      <td>-0.941383</td>\n",
       "      <td>-0.006075</td>\n",
       "      <td>-0.958925</td>\n",
       "      <td>0.239298</td>\n",
       "      <td>-0.067356</td>\n",
       "      <td>0.821048</td>\n",
       "      <td>0.426175</td>\n",
       "      <td>6.74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>90676.0</td>\n",
       "      <td>-2.405580</td>\n",
       "      <td>3.738235</td>\n",
       "      <td>-2.317843</td>\n",
       "      <td>1.367442</td>\n",
       "      <td>0.394001</td>\n",
       "      <td>1.919938</td>\n",
       "      <td>-3.106942</td>\n",
       "      <td>-10.764403</td>\n",
       "      <td>3.353525</td>\n",
       "      <td>...</td>\n",
       "      <td>10.005998</td>\n",
       "      <td>-2.454964</td>\n",
       "      <td>1.684957</td>\n",
       "      <td>0.118263</td>\n",
       "      <td>-1.531380</td>\n",
       "      <td>-0.695308</td>\n",
       "      <td>-0.152502</td>\n",
       "      <td>-0.138866</td>\n",
       "      <td>6.99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>34634.0</td>\n",
       "      <td>0.333499</td>\n",
       "      <td>1.699873</td>\n",
       "      <td>-2.596561</td>\n",
       "      <td>3.643945</td>\n",
       "      <td>-0.585068</td>\n",
       "      <td>-0.654659</td>\n",
       "      <td>-2.275789</td>\n",
       "      <td>0.675229</td>\n",
       "      <td>-2.042416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469212</td>\n",
       "      <td>-0.144363</td>\n",
       "      <td>-0.317981</td>\n",
       "      <td>-0.769644</td>\n",
       "      <td>0.807855</td>\n",
       "      <td>0.228164</td>\n",
       "      <td>0.551002</td>\n",
       "      <td>0.305473</td>\n",
       "      <td>18.96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>96135.0</td>\n",
       "      <td>-1.952933</td>\n",
       "      <td>3.541385</td>\n",
       "      <td>-1.310561</td>\n",
       "      <td>5.955664</td>\n",
       "      <td>-1.003993</td>\n",
       "      <td>0.983049</td>\n",
       "      <td>-4.587235</td>\n",
       "      <td>-4.892184</td>\n",
       "      <td>-2.516752</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.998091</td>\n",
       "      <td>1.133706</td>\n",
       "      <td>-0.041461</td>\n",
       "      <td>-0.215379</td>\n",
       "      <td>-0.865599</td>\n",
       "      <td>0.212545</td>\n",
       "      <td>0.532897</td>\n",
       "      <td>0.357892</td>\n",
       "      <td>18.96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>4462.0</td>\n",
       "      <td>-2.303350</td>\n",
       "      <td>1.759247</td>\n",
       "      <td>-0.359745</td>\n",
       "      <td>2.330243</td>\n",
       "      <td>-0.821628</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>0.562320</td>\n",
       "      <td>-0.399147</td>\n",
       "      <td>-0.238253</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294166</td>\n",
       "      <td>-0.932391</td>\n",
       "      <td>0.172726</td>\n",
       "      <td>-0.087330</td>\n",
       "      <td>-0.156114</td>\n",
       "      <td>-0.542628</td>\n",
       "      <td>0.039566</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>239.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0          282.0 -0.356466  0.725418  1.971749  0.831343  0.369681 -0.107776   \n",
       "1        14332.0  1.071950  0.340678  1.784068  2.846396 -0.751538  0.403028   \n",
       "2        32799.0  1.153477 -0.047859  1.358363  1.480620 -1.222598 -0.481690   \n",
       "3        35799.0 -0.769798  0.622325  0.242491 -0.586652  0.527819 -0.104512   \n",
       "4        36419.0  1.047960  0.145048  1.624573  2.932652 -0.726574  0.690451   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "284802  154599.0  0.667714  3.041502 -5.845112  5.967587  0.213863 -1.462923   \n",
       "284803   90676.0 -2.405580  3.738235 -2.317843  1.367442  0.394001  1.919938   \n",
       "284804   34634.0  0.333499  1.699873 -2.596561  3.643945 -0.585068 -0.654659   \n",
       "284805   96135.0 -1.952933  3.541385 -1.310561  5.955664 -1.003993  0.983049   \n",
       "284806    4462.0 -2.303350  1.759247 -0.359745  2.330243 -0.821628 -0.075788   \n",
       "\n",
       "              V7         V8        V9  ...        V21       V22       V23  \\\n",
       "0       0.751610  -0.120166 -0.420675  ...   0.020804  0.424312 -0.015989   \n",
       "1      -0.734920   0.205807  1.092726  ...  -0.169632 -0.113604  0.067643   \n",
       "2      -0.654461   0.128115  0.907095  ...   0.125514  0.480049 -0.025964   \n",
       "3       0.209909   0.669861 -0.304509  ...   0.152738  0.255654 -0.130237   \n",
       "4      -0.627288   0.278709  0.318434  ...   0.078499  0.658942 -0.067810   \n",
       "...          ...        ...       ...  ...        ...       ...       ...   \n",
       "284802 -2.688761   0.677764 -3.447596  ...   0.329760 -0.941383 -0.006075   \n",
       "284803 -3.106942 -10.764403  3.353525  ...  10.005998 -2.454964  1.684957   \n",
       "284804 -2.275789   0.675229 -2.042416  ...   0.469212 -0.144363 -0.317981   \n",
       "284805 -4.587235  -4.892184 -2.516752  ...  -1.998091  1.133706 -0.041461   \n",
       "284806  0.562320  -0.399147 -0.238253  ...  -0.294166 -0.932391  0.172726   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "0       0.466754 -0.809962  0.657334 -0.043150 -0.046401    0.00      0  \n",
       "1       0.468669  0.223541 -0.112355  0.014015  0.021504    0.00      0  \n",
       "2       0.701843  0.417245 -0.257691  0.060115  0.035332    0.00      0  \n",
       "3      -0.660934 -0.493374  0.331855 -0.011101  0.049089    0.00      0  \n",
       "4       0.476882  0.526830  0.219902  0.070627  0.028488    0.00      0  \n",
       "...          ...       ...       ...       ...       ...     ...    ...  \n",
       "284802 -0.958925  0.239298 -0.067356  0.821048  0.426175    6.74      1  \n",
       "284803  0.118263 -1.531380 -0.695308 -0.152502 -0.138866    6.99      1  \n",
       "284804 -0.769644  0.807855  0.228164  0.551002  0.305473   18.96      1  \n",
       "284805 -0.215379 -0.865599  0.212545  0.532897  0.357892   18.96      1  \n",
       "284806 -0.087330 -0.156114 -0.542628  0.039566 -0.153029  239.93      1  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21316443-e1ec-418a-885d-6d1f3105a0c1",
   "metadata": {},
   "source": [
    "## Train model on Vertex AI Workbench (JupyterLab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5707b149-4f88-4375-ba9b-878781b57eab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target = data[\"Class\"].astype(int)\n",
    "data.drop(\"Class\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfefa617-6cd7-40f3-81ae-4aa1c2aa2ee1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    284315\n",
       "1       492\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec82ed34-ae5d-4102-a67d-b3f6956a435c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data, target, train_size = 0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2794c3c-3d6b-4959-9c26-f52d022eab32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = pd.DataFrame(scaler.fit_transform(x_train), index=x_train.index, columns=x_train.columns)\n",
    "x_test = pd.DataFrame(scaler.transform(x_test), index=x_test.index, columns=x_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b78adaf9-6f78-4510-8918-67a8911079fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUCKET=\"astute-ace-336608-bucket\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eda5d66b-e5b5-479c-80a3-be8989db8b11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train_csv = pd.read_csv(f\"gs://{BUCKET}/vertex-data/x_train.csv\")\n",
    "y_train_csv = pd.read_csv(f\"gs://{BUCKET}/vertex-data/y_train.csv\")[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f10070e-1260-46ea-bd6f-6ada7e9e8264",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(x_train.shape[1],)),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "32455829-c38f-41a0-93cd-6d3c355a326c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fe766f-dc65-43ca-82d0-447ea05ffb80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "history = model.fit(x_train.values, y_train.values, \n",
    "                    epochs=4, \n",
    "                    batch_size=32, \n",
    "                    validation_split=0.2, \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1da51cb2-0612-4c73-9059-31c1629d3560",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss, auc = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2a7e55b-8524-4cb0-94a0-9134ddf38b46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1781/1781\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd796ddb-a360-4e77-8e08-5ff10abdb9bc",
   "metadata": {},
   "source": [
    "The next chunk evaluates a binary classifier using the area under the ROC curve. The ROC curve plots the true positive rate (TPR) vs. the false positive rate (FPR) at various thresholds. The AUC (area under the curve) is a single value between 0 and 1 that summarizes the model's performance, with higher values indicating better class separation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "01e66a41-9930-4de0-b748-62a6614c2e5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9587367603907067"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, preds)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e17cfb-569b-4d11-bad0-59fb1263bce2",
   "metadata": {},
   "source": [
    "That's not bad!\n",
    "\n",
    "What do you think about the performance of the model? Can you improve it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b25b68-2e7c-4760-b14c-8cd8ab891b7d",
   "metadata": {},
   "source": [
    "## Train and serve model on Vertex AI\n",
    "\n",
    "Custom training jobs (`CustomJob` resources in the Vertex AI API) are the basic way to run your custom machine learning (ML) training code in Vertex AI. In this lab, we will use a `CustomTrainingJob`, which runs a `CustomJob` and registers our model the the Vertex AI model registry. From the registry, a model can be deployed to an endpoint for online prediction or be used for batch prediction.\n",
    "\n",
    "Vertex AI offers [prebuilt containers](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers) to serve predictions and explanations from models trained using the following machine learning (ML) frameworks:\n",
    "\n",
    "* TensorFlow\n",
    "* PyTorch\n",
    "* XGBoost\n",
    "* scikit-learn\n",
    "\n",
    "To use one of these prebuilt containers, you must save your model as one or more model artifacts that comply with the requirements of the prebuilt container. These requirements apply whether or not your model artifacts are created on Vertex AI. In our case, this means we will upload the serialized model with file name `model.keras` to a location in Cloud Storage specified by the Vertex AI infrastructure (`AIP_MODEL_DIR`).\n",
    "\n",
    "To train the model on Vertex AI, let's first write our preprocessed data to Cloud Storage. There are a variety of ways of loading data in Vertex AI Training jobs. We opt for the simplest one and just upload it to Cloud Storage. However, in case of large data sets, you can write to tfrecords and stream them into your training job using a FUSE-mounted Cloud Storage directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9be20ef9-7e29-4cab-98c6-628315794c96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train.to_csv(f\"gs://{PROJECT_ID}-bucket/vertex-data/x_train.csv\", index=False)\n",
    "y_train.to_frame().to_csv(f\"gs://{PROJECT_ID}-bucket/vertex-data/y_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "60eca946-0dbb-4a83-bdab-4e492f4ae952",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating TabularDataset\n",
      "Create TabularDataset backing LRO: projects/888342260584/locations/us-central1/datasets/2745650409103163392/operations/9156516129248641024\n",
      "TabularDataset created. Resource name: projects/888342260584/locations/us-central1/datasets/2745650409103163392\n",
      "To use this TabularDataset in another session:\n",
      "ds = aiplatform.TabularDataset('projects/888342260584/locations/us-central1/datasets/2745650409103163392')\n"
     ]
    }
   ],
   "source": [
    "dataset = aiplatform.TabularDataset.create(\n",
    "    display_name=\"Bootkon Dataset\",\n",
    "    gcs_source=f\"gs://{PROJECT_ID}-bucket/vertex-data/x_train.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "188c35f7-2147-4f26-a7f3-4cf867398310",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "322f2819-118c-4fbc-8f12-88bcfa8a0625",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/train.py\n",
    "#!/usr/bin/env python\n",
    "# Train a simple neural network classifier on Vertex AI\n",
    "\n",
    "import os\n",
    "from pprint import pprint\n",
    "pprint(dict(os.environ))\n",
    "import random\n",
    "random.seed(1337)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from google.cloud import aiplatform, storage\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "\n",
    "BUCKET = os.environ[\"AIP_MODEL_DIR\"].split(\"/\")[2]\n",
    "\n",
    "aiplatform.init(project=os.environ[\"CLOUD_ML_PROJECT_ID\"],\n",
    "                location=os.environ[\"CLOUD_ML_REGION\"],\n",
    "                staging_bucket=BUCKET)\n",
    "\n",
    "# Load data\n",
    "x_train = pd.read_csv(f\"gs://{BUCKET}/vertex-data/x_train.csv\")\n",
    "y_train = pd.read_csv(f\"gs://{BUCKET}/vertex-data/y_train.csv\")[\"Class\"]\n",
    "\n",
    "# Train model\n",
    "model = Sequential([\n",
    "    Input(shape=(x_train.shape[1],)),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(8, activation='relu'),  # Hidden layer with 8 neurons\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['auc'])\n",
    "\n",
    "history = model.fit(x_train.values, y_train.values, \n",
    "                    epochs=4, \n",
    "                    batch_size=32, \n",
    "                    validation_split=0.2, \n",
    "                    verbose=1)\n",
    "\n",
    "# Upload model to Cloud Storage\n",
    "model.save(\"model.keras\")\n",
    "client = storage.Client(project=os.environ[\"CLOUD_ML_PROJECT_ID\"])\n",
    "bucket = client.get_bucket(BUCKET)\n",
    "blob = bucket.blob(\"/\".join(os.environ[\"AIP_MODEL_DIR\"].split(\"/\")[3:][:-1] + [\"model.keras\"]))\n",
    "blob.upload_from_filename(\"model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6f47a647-f6d9-4bb9-865c-cf28b1fb41c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/serve.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/serve.py\n",
    "\n",
    "print(\"foo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d96c88eb-572b-4986-b6df-e13784c40158",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/Dockerfile\n",
    "FROM us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-17.py310\n",
    "\n",
    "WORKDIR /root\n",
    "\n",
    "COPY train.py /root/train.py\n",
    "COPY serve.py /root/serve.py\n",
    "\n",
    "EXPOSE 8080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c0ed9e40-058a-4850-8921-458e3aef5a3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMAGE_URI = f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/bootkon/bootkon:latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c9a6faa7-243c-48f1-99b3-d77f271a2242",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mERROR:\u001b[0m (gcloud.artifacts.repositories.create) ALREADY_EXISTS: the repository already exists\n"
     ]
    }
   ],
   "source": [
    "!gcloud artifacts repositories create bootkon --repository-format=docker --location={REGION} --description=\"Bootkon repository\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "286411b6-e0fa-4134-8010-4c585d483ff4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 Âµs, sys: 1 Âµs, total: 5 Âµs\n",
      "Wall time: 11.2 Âµs\n",
      "Creating temporary archive of 3 file(s) totalling 1.7 KiB before compression.\n",
      "Uploading tarball of [.] to [gs://astute-ace-336608_cloudbuild/source/1737449826.339065-ace128e5b57d40a5ac858f5b98afb0bf.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/astute-ace-336608/locations/us-central1/builds/13bcf128-7726-4710-b8c8-4878e9990c17].\n",
      "Logs are available at [ https://console.cloud.google.com/cloud-build/builds;region=us-central1/13bcf128-7726-4710-b8c8-4878e9990c17?project=888342260584 ].\n",
      "Waiting for build to complete. Polling interval: 1 second(s).\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"13bcf128-7726-4710-b8c8-4878e9990c17\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://astute-ace-336608_cloudbuild/source/1737449826.339065-ace128e5b57d40a5ac858f5b98afb0bf.tgz#1737449826634993\n",
      "Copying gs://astute-ace-336608_cloudbuild/source/1737449826.339065-ace128e5b57d40a5ac858f5b98afb0bf.tgz#1737449826634993...\n",
      "/ [1 files][  1.1 KiB/  1.1 KiB]                                                \n",
      "Operation completed over 1 objects/1.1 KiB.\n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  5.632kB\n",
      "Step 1/5 : FROM us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-17.py310\n",
      "latest: Pulling from deeplearning-platform-release/gcr.io/tf2-cpu.2-17.py310\n",
      "86e5016c2693: Pulling fs layer\n",
      "a59ca6348a1e: Pulling fs layer\n",
      "881002d2fcae: Pulling fs layer\n",
      "4f4fb700ef54: Pulling fs layer\n",
      "0408076cdfd4: Pulling fs layer\n",
      "282817e042fe: Pulling fs layer\n",
      "9ffbffb84c75: Pulling fs layer\n",
      "211fab8c823a: Pulling fs layer\n",
      "cf1a992e0adb: Pulling fs layer\n",
      "0820ddca72ac: Pulling fs layer\n",
      "28eddb76ef77: Pulling fs layer\n",
      "270aede0d2c5: Pulling fs layer\n",
      "bc8bab722ee8: Pulling fs layer\n",
      "0aa36bf1c368: Pulling fs layer\n",
      "89d9afa23f1e: Pulling fs layer\n",
      "c1fd6f28a250: Pulling fs layer\n",
      "7215d8ed7f4d: Pulling fs layer\n",
      "d0797841ea57: Pulling fs layer\n",
      "2873508f6241: Pulling fs layer\n",
      "997b8f1fff8d: Pulling fs layer\n",
      "b2a03e217b73: Pulling fs layer\n",
      "a9109c6ac5bc: Pulling fs layer\n",
      "ceb0ff3f40f3: Pulling fs layer\n",
      "509fac6f34b5: Pulling fs layer\n",
      "4b0b94cf5a9d: Pulling fs layer\n",
      "ce8e2d0f61f8: Pulling fs layer\n",
      "a1fc1b3a7df5: Pulling fs layer\n",
      "caa30f1881a4: Pulling fs layer\n",
      "ef3eff0a501a: Pulling fs layer\n",
      "8585dc157cb6: Pulling fs layer\n",
      "0408076cdfd4: Waiting\n",
      "282817e042fe: Waiting\n",
      "9ffbffb84c75: Waiting\n",
      "211fab8c823a: Waiting\n",
      "cf1a992e0adb: Waiting\n",
      "0820ddca72ac: Waiting\n",
      "28eddb76ef77: Waiting\n",
      "270aede0d2c5: Waiting\n",
      "bc8bab722ee8: Waiting\n",
      "0aa36bf1c368: Waiting\n",
      "89d9afa23f1e: Waiting\n",
      "c1fd6f28a250: Waiting\n",
      "7215d8ed7f4d: Waiting\n",
      "d0797841ea57: Waiting\n",
      "2873508f6241: Waiting\n",
      "997b8f1fff8d: Waiting\n",
      "b2a03e217b73: Waiting\n",
      "a9109c6ac5bc: Waiting\n",
      "ceb0ff3f40f3: Waiting\n",
      "509fac6f34b5: Waiting\n",
      "4b0b94cf5a9d: Waiting\n",
      "ce8e2d0f61f8: Waiting\n",
      "a1fc1b3a7df5: Waiting\n",
      "caa30f1881a4: Waiting\n",
      "ef3eff0a501a: Waiting\n",
      "8585dc157cb6: Waiting\n",
      "4f4fb700ef54: Waiting\n",
      "881002d2fcae: Verifying Checksum\n",
      "881002d2fcae: Download complete\n",
      "4f4fb700ef54: Download complete\n",
      "86e5016c2693: Verifying Checksum\n",
      "86e5016c2693: Download complete\n",
      "a59ca6348a1e: Verifying Checksum\n",
      "a59ca6348a1e: Download complete\n",
      "9ffbffb84c75: Verifying Checksum\n",
      "9ffbffb84c75: Download complete\n",
      "211fab8c823a: Verifying Checksum\n",
      "211fab8c823a: Download complete\n",
      "cf1a992e0adb: Verifying Checksum\n",
      "cf1a992e0adb: Download complete\n",
      "0820ddca72ac: Verifying Checksum\n",
      "0820ddca72ac: Download complete\n",
      "28eddb76ef77: Download complete\n",
      "282817e042fe: Verifying Checksum\n",
      "282817e042fe: Download complete\n",
      "bc8bab722ee8: Verifying Checksum\n",
      "bc8bab722ee8: Download complete\n",
      "0aa36bf1c368: Verifying Checksum\n",
      "0aa36bf1c368: Download complete\n",
      "89d9afa23f1e: Verifying Checksum\n",
      "89d9afa23f1e: Download complete\n",
      "c1fd6f28a250: Download complete\n",
      "7215d8ed7f4d: Verifying Checksum\n",
      "7215d8ed7f4d: Download complete\n",
      "d0797841ea57: Verifying Checksum\n",
      "d0797841ea57: Download complete\n",
      "2873508f6241: Verifying Checksum\n",
      "2873508f6241: Download complete\n",
      "997b8f1fff8d: Verifying Checksum\n",
      "997b8f1fff8d: Download complete\n",
      "b2a03e217b73: Verifying Checksum\n",
      "b2a03e217b73: Download complete\n",
      "a9109c6ac5bc: Verifying Checksum\n",
      "a9109c6ac5bc: Download complete\n",
      "0408076cdfd4: Verifying Checksum\n",
      "0408076cdfd4: Download complete\n",
      "509fac6f34b5: Verifying Checksum\n",
      "509fac6f34b5: Download complete\n",
      "4b0b94cf5a9d: Verifying Checksum\n",
      "4b0b94cf5a9d: Download complete\n",
      "ce8e2d0f61f8: Verifying Checksum\n",
      "ce8e2d0f61f8: Download complete\n",
      "86e5016c2693: Pull complete\n",
      "270aede0d2c5: Verifying Checksum\n",
      "270aede0d2c5: Download complete\n",
      "caa30f1881a4: Download complete\n",
      "ef3eff0a501a: Verifying Checksum\n",
      "ef3eff0a501a: Download complete\n",
      "8585dc157cb6: Verifying Checksum\n",
      "8585dc157cb6: Download complete\n",
      "a1fc1b3a7df5: Download complete\n",
      "a59ca6348a1e: Pull complete\n",
      "881002d2fcae: Pull complete\n",
      "4f4fb700ef54: Pull complete\n",
      "0408076cdfd4: Pull complete\n",
      "ceb0ff3f40f3: Verifying Checksum\n",
      "ceb0ff3f40f3: Download complete\n",
      "282817e042fe: Pull complete\n",
      "9ffbffb84c75: Pull complete\n",
      "211fab8c823a: Pull complete\n",
      "cf1a992e0adb: Pull complete\n",
      "0820ddca72ac: Pull complete\n",
      "28eddb76ef77: Pull complete\n",
      "270aede0d2c5: Pull complete\n",
      "bc8bab722ee8: Pull complete\n",
      "0aa36bf1c368: Pull complete\n",
      "89d9afa23f1e: Pull complete\n",
      "c1fd6f28a250: Pull complete\n",
      "7215d8ed7f4d: Pull complete\n",
      "d0797841ea57: Pull complete\n",
      "2873508f6241: Pull complete\n",
      "997b8f1fff8d: Pull complete\n",
      "b2a03e217b73: Pull complete\n",
      "a9109c6ac5bc: Pull complete\n",
      "ceb0ff3f40f3: Pull complete\n",
      "509fac6f34b5: Pull complete\n",
      "4b0b94cf5a9d: Pull complete\n",
      "ce8e2d0f61f8: Pull complete\n",
      "a1fc1b3a7df5: Pull complete\n",
      "caa30f1881a4: Pull complete\n",
      "ef3eff0a501a: Pull complete\n",
      "8585dc157cb6: Pull complete\n",
      "Digest: sha256:03cfe37192f25f540519a2364cc9c87a3007311ad3c16112b094ccce2202d6bb\n",
      "Status: Downloaded newer image for us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-17.py310:latest\n",
      " ---> 7319468d8691\n",
      "Step 2/5 : WORKDIR /root\n",
      " ---> Running in 636da31a6858\n",
      "Removing intermediate container 636da31a6858\n",
      " ---> 3e5dd52dced8\n",
      "Step 3/5 : COPY train.py /root/train.py\n",
      " ---> e5b896c76676\n",
      "Step 4/5 : COPY serve.py /root/serve.py\n",
      " ---> c74b4e7a8eba\n",
      "Step 5/5 : EXPOSE 8080\n",
      " ---> Running in a7fc1459a3e4\n",
      "Removing intermediate container a7fc1459a3e4\n",
      " ---> ba5ca34e48e9\n",
      "Successfully built ba5ca34e48e9\n",
      "Successfully tagged us-central1-docker.pkg.dev/astute-ace-336608/bootkon/bootkon:latest\n",
      "PUSH\n",
      "Pushing us-central1-docker.pkg.dev/astute-ace-336608/bootkon/bootkon:latest\n",
      "The push refers to repository [us-central1-docker.pkg.dev/astute-ace-336608/bootkon/bootkon]\n",
      "cd3890c540d8: Preparing\n",
      "a53ede2ec6a3: Preparing\n",
      "3da5d79dcaa6: Preparing\n",
      "e7f69f448642: Preparing\n",
      "4cc2b1a9f026: Preparing\n",
      "224806b2e543: Preparing\n",
      "fee32320eafe: Preparing\n",
      "87314f578912: Preparing\n",
      "6b8ecd10a702: Preparing\n",
      "5f70bf18a086: Preparing\n",
      "fdfe4e47d3e8: Preparing\n",
      "ace5a7a3f7c0: Preparing\n",
      "639e2e4d46b8: Preparing\n",
      "932c150d8913: Preparing\n",
      "852eb0e0f29e: Preparing\n",
      "cabeee7fad39: Preparing\n",
      "2104f7c8d7ee: Preparing\n",
      "de30c480565c: Preparing\n",
      "8cf7d05cdf13: Preparing\n",
      "d507c6367b2d: Preparing\n",
      "629f1302b5d2: Preparing\n",
      "38e1a0584d9c: Preparing\n",
      "d00ce7f00930: Preparing\n",
      "6f96a8f411c3: Preparing\n",
      "b31aba0f6fa7: Preparing\n",
      "4e718bee1d58: Preparing\n",
      "11ac51881ec3: Preparing\n",
      "5f70bf18a086: Preparing\n",
      "fe33d1d7f674: Preparing\n",
      "5b344571b8af: Preparing\n",
      "5f70bf18a086: Preparing\n",
      "2746868f0b5f: Preparing\n",
      "dcb3fb08fe02: Preparing\n",
      "fffe76c64ef2: Preparing\n",
      "87314f578912: Waiting\n",
      "6b8ecd10a702: Waiting\n",
      "5f70bf18a086: Waiting\n",
      "fdfe4e47d3e8: Waiting\n",
      "ace5a7a3f7c0: Waiting\n",
      "639e2e4d46b8: Waiting\n",
      "932c150d8913: Waiting\n",
      "852eb0e0f29e: Waiting\n",
      "cabeee7fad39: Waiting\n",
      "2104f7c8d7ee: Waiting\n",
      "de30c480565c: Waiting\n",
      "8cf7d05cdf13: Waiting\n",
      "d507c6367b2d: Waiting\n",
      "629f1302b5d2: Waiting\n",
      "38e1a0584d9c: Waiting\n",
      "d00ce7f00930: Waiting\n",
      "6f96a8f411c3: Waiting\n",
      "b31aba0f6fa7: Waiting\n",
      "4e718bee1d58: Waiting\n",
      "11ac51881ec3: Waiting\n",
      "fe33d1d7f674: Waiting\n",
      "5b344571b8af: Waiting\n",
      "2746868f0b5f: Waiting\n",
      "dcb3fb08fe02: Waiting\n",
      "fffe76c64ef2: Waiting\n",
      "224806b2e543: Waiting\n",
      "fee32320eafe: Waiting\n",
      "3da5d79dcaa6: Layer already exists\n",
      "e7f69f448642: Layer already exists\n",
      "4cc2b1a9f026: Layer already exists\n",
      "87314f578912: Layer already exists\n",
      "224806b2e543: Layer already exists\n",
      "fee32320eafe: Layer already exists\n",
      "6b8ecd10a702: Layer already exists\n",
      "5f70bf18a086: Layer already exists\n",
      "fdfe4e47d3e8: Layer already exists\n",
      "ace5a7a3f7c0: Layer already exists\n",
      "a53ede2ec6a3: Pushed\n",
      "639e2e4d46b8: Layer already exists\n",
      "cd3890c540d8: Pushed\n",
      "932c150d8913: Layer already exists\n",
      "852eb0e0f29e: Layer already exists\n",
      "cabeee7fad39: Layer already exists\n",
      "2104f7c8d7ee: Layer already exists\n",
      "8cf7d05cdf13: Layer already exists\n",
      "d507c6367b2d: Layer already exists\n",
      "de30c480565c: Layer already exists\n",
      "629f1302b5d2: Layer already exists\n",
      "d00ce7f00930: Layer already exists\n",
      "38e1a0584d9c: Layer already exists\n",
      "6f96a8f411c3: Layer already exists\n",
      "b31aba0f6fa7: Layer already exists\n",
      "4e718bee1d58: Layer already exists\n",
      "11ac51881ec3: Layer already exists\n",
      "2746868f0b5f: Layer already exists\n",
      "5b344571b8af: Layer already exists\n",
      "fe33d1d7f674: Layer already exists\n",
      "fffe76c64ef2: Layer already exists\n",
      "dcb3fb08fe02: Layer already exists\n",
      "latest: digest: sha256:c21ed04963d201092aac77b9b4ef7b309e70e58fb91c39942e7d3c74896fc729 size: 7428\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                           IMAGES                                                                  STATUS\n",
      "13bcf128-7726-4710-b8c8-4878e9990c17  2025-01-21T08:57:06+00:00  4M4S      gs://astute-ace-336608_cloudbuild/source/1737449826.339065-ace128e5b57d40a5ac858f5b98afb0bf.tgz  us-central1-docker.pkg.dev/astute-ace-336608/bootkon/bootkon (+1 more)  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "!cd src && gcloud builds submit --region={REGION} --tag={IMAGE_URI} --timeout=1h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "13a24ac5-2295-4006-b1fb-3fd40b23d3c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_id = 1 if \"run_id\" not in vars() else run_id + 1\n",
    "\n",
    "job = aiplatform.CustomContainerTrainingJob(\n",
    "    display_name=f\"bootkon-run-{run_id}\",\n",
    "    container_uri=IMAGE_URI,\n",
    "    command=[\"python\", \"train.py\"],\n",
    "    model_serving_container_image_uri=IMAGE_URI,\n",
    "    model_serving_container_command=[\"python\", \"serve.py\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b7ba8f-19d1-4f75-8353-4db8b32aafe4",
   "metadata": {},
   "source": [
    "Let's run the training job! It will take around 6 minutes, but the provisioning of the job may take longer if there are a lot of people requesting resources at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823ca126-1d7a-4d8f-bbcf-b974c3d16a3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 Âµs, sys: 1 Âµs, total: 5 Âµs\n",
      "Wall time: 16 Âµs\n",
      "Training Output directory:\n",
      "gs://astute-ace-336608-bucket/aiplatform-custom-training-2025-01-21-09:07:39.362 \n",
      "No dataset split provided. The service will use a default split.\n",
      "View Training:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/1337978623050645504?project=888342260584\n",
      "CustomContainerTrainingJob projects/888342260584/locations/us-central1/trainingPipelines/1337978623050645504 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomContainerTrainingJob projects/888342260584/locations/us-central1/trainingPipelines/1337978623050645504 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomContainerTrainingJob projects/888342260584/locations/us-central1/trainingPipelines/1337978623050645504 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomContainerTrainingJob projects/888342260584/locations/us-central1/trainingPipelines/1337978623050645504 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomContainerTrainingJob projects/888342260584/locations/us-central1/trainingPipelines/1337978623050645504 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "View backing custom job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/3834186677450964992?project=888342260584\n",
      "CustomContainerTrainingJob projects/888342260584/locations/us-central1/trainingPipelines/1337978623050645504 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "vertex_model = job.run(\n",
    "    machine_type=\"n2-standard-4\",\n",
    "    replica_count=1,\n",
    "    dataset=dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c236ac0c-601b-468a-8c5d-890fe19955b5",
   "metadata": {},
   "source": [
    "While it is running, please go to the [`Training Jobs` in the Vertex AI Console](https://console.cloud.google.com/vertex-ai/training/training-pipelines) and click on the training job where you see **Status: Training**. The training job is based on a more general concept called `CustomJob` and adds functionality such as automatic model upload to Cloud Storage and registering the model to the model registry. Hence, to see details about the running job, click on the **Custom Job** and then **View Logs**.\n",
    "\n",
    "Once the model has been trained, navigate to the [`Model Registry` in Vertex AI](https://console.cloud.google.com/vertex-ai/models). Click on `bootkon-model`. Can you find your newly created model artifact? Open the `VERSION DETAILS` tab and try to find your `model.keras` artifact on Cloud Storage.\n",
    "\n",
    "Next, create an endpoint to perform online predictions. The creation will take around 6min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bf8e27-b7b6-42a8-ad0d-da43cb497896",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = vertex_model.deploy(machine_type=\"n2-standard-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f9656b-e09e-4dfe-bc24-8f649604499e",
   "metadata": {},
   "source": [
    "Go to [`Endpoints` in Vertex AI](https://console.cloud.google.com/vertex-ai/endpoints). Notice how the above command first creates an `Endpoint` and then deploys our `Model` to this endpoint.\n",
    "\n",
    "Let's make a prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b932f9-da32-407a-b9cb-19abc37a9192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3da18712-9d78-4ad9-8ef6-f38a41bf4506",
   "metadata": {},
   "source": [
    "Interested in how to make a prediction using the standard REST API? Go back to [`Endpoints` in Vertex AI](https://console.cloud.google.com/vertex-ai/endpoints) and click on `SAMPLE REQUEST` next to your endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5430aa2b-05e2-46c5-976f-f73a33403823",
   "metadata": {},
   "source": [
    "## Train and serve model on Vertex AI through Vertex AI Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d5a071-b171-4ebf-b3ee-2cb547b9ea95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m126",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m126"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
